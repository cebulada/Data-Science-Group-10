{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Purpose\n",
    "- read the .csv.gz compressed file dataset into pandas DataFrame and perform analyses and visualizations on the dataset\n",
    "    - explore dataset features and labels to find trends that Toronto Fire Services (TFS) Basic Incidents follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 10 Members\n",
    "\n",
    "- ### A. Nidhi Punja - [Email](mailto:npunja@uwaterloo.ca)\n",
    "- ### B. Judith Roth - [Email](mailto:j5roth@uwaterloo.ca)\n",
    "- ### C. Iman Dordizadeh Basirabad - [Email](mailto:idordiza@uwaterloo.ca)\n",
    "- ### D. Daniel Adam Cebula - [Email](mailto:dacebula@uwaterloo.ca)\n",
    "- ### E. Cynthia Fung - [Email](mailto:c27fung@uwaterloo.ca)\n",
    "- ### F. Ben Klassen - [Email](mailto:b6klasse@uwaterloo.ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group 10 Collaborators\n",
    "COLLABORATORS = [\"Nidhi Punja\",\n",
    "                 \"Judith Roth\",\n",
    "                 \"Iman Dordizadeh Basirabad\",\n",
    "                 \"Daniel Adam Cebula\",\n",
    "                 \"Cynthia Fung\",\n",
    "                 \"Ben Klassen\"]\n",
    "\n",
    "# Group 10 Members\n",
    "for _ in COLLABORATORS:\n",
    "    print(f\"Group 10 Member: {_:->30}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "## 1. [Python Dependecies](#1.-Python-Libraries-and-Dependencies[1,2,3,4,5,6])\n",
    "___\n",
    "## 2. [Folder Creation](#2.-Folder-Creation-for-Data-Analyses-and-Visualization)\n",
    "___\n",
    "## 3. [Read in the Data](#3.-Read-in-DataSet-as-a-Pandas-DataFrame)\n",
    "___\n",
    "## 4. [Toronto Fire Services (TFS) Incident Types](#4.-Toronto-Fire-Services-(TFS)-Incident-Type-Exploration)\n",
    "___\n",
    "## 5. [Toronto Fire Services (TFS) Time Series](#5.-Toronto-Fire-Services-Time-Series-Exploration)\n",
    "___\n",
    "## 6. [Weather / Climate effect on TFS Fire Incidents](#6.-The-Effect-of-Toronto-Weather-/-Climate-on-Toronto-Fire-Services-Basic-Incidents)\n",
    "___\n",
    "## 7. [Time and Days of the Week effect on TFS Fire Incidents](#7.-The-effect-if-Time-and-Day-of-the-Week-on-TFS-Fire-Incidents)\n",
    "\n",
    "\n",
    "\n",
    "## 7. [References](#7.-Jupyter-Notebook-References)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Python Libraries and Dependencies<sup>[1,2,3,4,5,6]</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Modules for Miscellaneous reasons\n",
    "import os        # portable way to use operating system functionalities\n",
    "import datetime  # python classes for manipulating dates and times\n",
    "import dateutil  # powerful extensions to standard datetime Python module\n",
    "import re        # used for Python regex library\n",
    "from IPython.display import display # use this to see the entire DataFrame in the right format\n",
    "from create_folder import create_folder # create folder function that I have defined and placed in create_folder.py file\n",
    "import warnings  # suppress warnings from various Python libraries\n",
    "import math      # import python math library for various functions\n",
    "import string    # use this library to remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA ANALYSIS / VISUALIZATION Python Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn data visualization library based on matplotlib\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some matplotlib libraries for formatting\n",
    "import matplotlib.ticker as tick\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Folder Creation for Data Analyses and Visualization\n",
    "- generate a folder that will hold data analyses / visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a connection to the major directory holding the data / metadata of the DataFrame\n",
    "PROCESSED_ZIPPED_DIRECTORY = create_folder(folder_name=\"PROCESSED_ZIPPED\")\n",
    "\n",
    "# generate a images folder and a analyses folder to hold all relevant information\n",
    "IMAGES_DIRECTORY = create_folder(folder_name=\"IMAGES\")\n",
    "ANALYSES_DIRECTORY = create_folder(folder_name=\"ANALYSES\")\n",
    "\n",
    "# get folders for fire incidents, toronto weather and fire station location data\n",
    "FIRE_PROCESSED_ZIPPED_DIRECTORY = create_folder(folder_name=os.path.join(PROCESSED_ZIPPED_DIRECTORY, \"FIRE_INCIDENTS\"))\n",
    "WEATHER_PROCESSED_ZIPPED_DIRECTORY = create_folder(folder_name=os.path.join(PROCESSED_ZIPPED_DIRECTORY, \"TORONTO_WEATHER\"))\n",
    "STATIONS_PROCESSED_ZIPPED_DIRECTORY = create_folder(folder_name=os.path.join(PROCESSED_ZIPPED_DIRECTORY, \"FIRE_STATIONS\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Read in DataSet as a Pandas DataFrame\n",
    "- DataSet is a compressed file (.csv.bz2)\n",
    "- DataSet Metadata is a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the metadata from .csv into memory\n",
    "# use this metatdata to explain the columns\n",
    "df_metadata = pd.read_csv(\n",
    "    os.path.join(FIRE_PROCESSED_ZIPPED_DIRECTORY, \"FINAL_DATASET_METADATA.csv\"),\n",
    "    index_col=\"COLUMN_NAME\")\n",
    "\n",
    "# display it\n",
    "with pd.option_context('display.max_colwidth', 300):\n",
    "    display(df_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the merged DataFrame from .csv.bz2 file into DataFrame\n",
    "PATH_MERGED_CSV_BZ2 = os.path.join(FIRE_PROCESSED_ZIPPED_DIRECTORY, \"FINAL_DATASET.csv.bz2\")\n",
    "\n",
    "# pandas DataFrame generated and is referenced by df variable name\n",
    "df = pd.read_csv(PATH_MERGED_CSV_BZ2,\n",
    "                 compression='bz2', index_col=\"INCIDENT_NUM\", parse_dates=[\"DATETIME\"])\n",
    "\n",
    "# make the columns categorical (for faster queries)\n",
    "df[\"CAD_TYPE\"] = pd.Categorical(df[\"CAD_TYPE\"])\n",
    "df[\"CAD_CALL_TYPE\"] = pd.Categorical(df[\"CAD_CALL_TYPE\"])\n",
    "df[\"FINAL_TYPE\"] = pd.Categorical(df[\"FINAL_TYPE\"])\n",
    "df[\"CALL_SOURCE\"] = pd.Categorical(df[\"CALL_SOURCE\"])\n",
    "df[\"NAME\"] = pd.Categorical(df[\"NAME\"])\n",
    "df[\"ADDRESS\"] = pd.Categorical(df[\"ADDRESS\"])\n",
    "df[\"WARD_NAME\"] = pd.Categorical(df[\"WARD_NAME\"])\n",
    "df[\"MUN_NAME\"] = pd.Categorical(df[\"MUN_NAME\"])\n",
    "\n",
    "# display it\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Toronto Fire Services (TFS) Incident Type Exploration\n",
    "- What are the majority of calls for TFS basic fire incidents?\n",
    "    - 69 Total Final Incident Types\n",
    "    - Top 15 are ~91% and Top 10 are ~85.5%\n",
    "    - Fire is number 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lets get the total observations for each category in  \"FINAL_TYPE\" column\n",
    "df_FINAL_TYPE = pd.DataFrame(df[\"FINAL_TYPE\"].value_counts()\n",
    "                                             .reset_index()\n",
    "                                             .rename(columns={\n",
    "                                                 \"index\":\"FINAL_TYPE\",\n",
    "                                                 \"FINAL_TYPE\":\"COUNT\"}))\n",
    "\n",
    "# set the index to start from 1 and set index name\n",
    "df_FINAL_TYPE = df_FINAL_TYPE.set_index(np.arange(1, len(df_FINAL_TYPE)+1))\n",
    "df_FINAL_TYPE.index.name = \"INDEX\"\n",
    "\n",
    "# Create a \"CODE\" and \"DESCRIPTION\" column that splits the number and description from each other\n",
    "df_FINAL_TYPE[\"CODE\"] = df_FINAL_TYPE[\"FINAL_TYPE\"].apply(lambda x: int(x.split(\"-\")[0].strip()))\n",
    "df_FINAL_TYPE[\"DESCRIPTION\"] = df_FINAL_TYPE[\"FINAL_TYPE\"].apply(lambda x: x.split(\"-\")[1].strip())\n",
    "\n",
    "# create a slice dropping FINAL_TYPE column and Reordering the rest\n",
    "df_FINAL_TYPE = df_FINAL_TYPE.loc[:, [\"CODE\", \"DESCRIPTION\", \"COUNT\"]]\n",
    "\n",
    "# display all the rows\n",
    "with pd.option_context(\"display.max_rows\", None):\n",
    "    display(df_FINAL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The top 15 Final Incident Types account for ~91% of all Basic Fire Incidents\n",
    "print(f\"\"\"Top 15 Final Incident Types account for:  \"\"\" +\n",
    "      f\"\"\"{(sum(df_FINAL_TYPE[\"COUNT\"][:15]) / sum(df_FINAL_TYPE[\"COUNT\"])):.2%}\"\"\"+\n",
    "      \"\"\" of all Basic Fire Incidents.\\n\\n\"\"\")\n",
    "\n",
    "# And Number 11 is Fire\n",
    "display(df_FINAL_TYPE.loc[11])\n",
    "\n",
    "# The top 10 Final Incident Types account for ~85.5% of all Basic Fire Incidents\n",
    "# Toronto Fire Services might be wise to change their name to Toronto Emergency Services instead...\n",
    "print(f\"\"\"\\n\\nTop 10 Final Incident Types account for:  \"\"\" +\n",
    "      f\"\"\"{(sum(df_FINAL_TYPE[\"COUNT\"][:10]) / sum(df_FINAL_TYPE[\"COUNT\"])):.2%}\"\"\"+\n",
    "      \"\"\" of all Basic Fire Incidents.\\n\\n\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\") # suppress SetwithCopy Warnings from Pandas\n",
    "    \n",
    "    # generate 2 columns that provide percentage of total calls received for\n",
    "    # types of calls\n",
    "    df_FINAL_TYPE_15 = df_FINAL_TYPE.loc[:15]\n",
    "\n",
    "    # Total Calls\n",
    "    df_FINAL_TYPE_15[\"TOTAL_CALLS_RECEIVED_%\"] = df_FINAL_TYPE_15[\"COUNT\"].apply(\n",
    "                            lambda x: f\"{str(np.floor(np.around(x / np.sum(df_FINAL_TYPE['COUNT']), decimals=2) * 100))}%\"\n",
    "                                                                                 )\n",
    "    # Top 15 Calls\n",
    "    df_FINAL_TYPE_15[\"TOP_15_CALLS_RECEIVED_%\"] = df_FINAL_TYPE_15[\"COUNT\"].apply(\n",
    "                            lambda x: f\"{str(np.floor(np.around(x / np.sum(df_FINAL_TYPE['COUNT'][:15]), decimals=2) * 100))}%\"\n",
    "                                                                                 )\n",
    "\n",
    "    display(df_FINAL_TYPE_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\") # suppress SetwithCopy Warnings from Pandas\n",
    "    # append a Total Count to the Bottom\n",
    "    df_FINAL_TYPE_15.loc[\"Total\"] = df_FINAL_TYPE_15[[\"COUNT\"]].sum()\n",
    "\n",
    "    # Save the DataFrame to .csv file\n",
    "    # Save the DataFrame to a .csv file\n",
    "    df_FINAL_TYPE_15.to_csv(os.path.join(ANALYSES_DIRECTORY, \"TFS_Final_Incident_Types.csv\"))\n",
    "\n",
    "    display(df_FINAL_TYPE_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up memory\n",
    "del df_FINAL_TYPE_15, df_FINAL_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Toronto Fire Services Time Series Exploration\n",
    "- Data has timestamps from January 2011 to December 2018\n",
    "    - lets explore how many basic fire incidents the TFS responds to on a daily / monthly basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a slice of the DataFrame and make a copy of the data\n",
    "# since the count is take all we needs is a column with no nulls\n",
    "# CAD_TYPE was chosen\n",
    "df_DATETIME = df.loc[:, [\"DATETIME\", \"CAD_TYPE\"]].copy()\n",
    "\n",
    "# set the index as the \"DATETIME\" column which contains the timestamps\n",
    "# drop the DATETIME column as it is now the index\n",
    "df_DATETIME.index = df[\"DATETIME\"]\n",
    "df_DATETIME = df_DATETIME.drop(columns=\"DATETIME\")\n",
    "\n",
    "# resample dailyand get the daily count of TFS Basic Fire Incidents\n",
    "df_DATETIME_DAILY = df_DATETIME.resample(\"D\").count().rename(columns={\"CAD_TYPE\":\"COUNT\"})\n",
    "df_DATETIME_DAILY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the resampled daily count time series with matplotlib\n",
    "fig, axes = plt.subplots(1, 1, figsize=(7, 3.5))\n",
    "\n",
    "# get y lim\n",
    "y_lim1 = 0\n",
    "y_lim2 = math.ceil(df_DATETIME_DAILY[\"COUNT\"].max() / 1000) * 1000\n",
    "\n",
    "# get x lim\n",
    "x_lim1 = datetime.datetime(year=2010, month=10, day=1)\n",
    "x_lim2 = datetime.datetime(year=2019, month=2, day=1)\n",
    "\n",
    "# plot the time series\n",
    "axes.plot(df_DATETIME_DAILY.index,\n",
    "          df_DATETIME_DAILY[\"COUNT\"],\n",
    "          color=\"blue\",\n",
    "          linewidth=0.5,\n",
    "          label=\"Daily Call Counts for TFS\");\n",
    "\n",
    "# set axis limits\n",
    "axes.set_xlim(x_lim1, x_lim2)\n",
    "axes.set_ylim(y_lim1, y_lim2)\n",
    "\n",
    "# set minor ticks for x axis to be the months\n",
    "months = mdates.MonthLocator()\n",
    "axes.xaxis.set_minor_locator(months)\n",
    "\n",
    "# set minor ticks for y axis to be values of 100\n",
    "hundreds = tick.MultipleLocator(100)\n",
    "axes.yaxis.set_minor_locator(hundreds)\n",
    "\n",
    "# set title, x axis title and y axis title\n",
    "axes.set_title(\"Daily Total Calls Received by the Toronto Fire Services (TFS)\")\n",
    "axes.set_xlabel(\"Years (2011 - 2018 range)\")\n",
    "axes.set_ylabel(\"Number of Daily Calls\")\n",
    "\n",
    "# plot a legend\n",
    "plt.legend()\n",
    "\n",
    "# magical padding\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the figure\n",
    "fig.savefig(os.path.join(IMAGES_DIRECTORY, \"Daily_Total_Calls_TFS.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There appears to be a maximum (outlier?) in December 22 2013\n",
    "df_DATETIME_DAILY.loc[df_DATETIME_DAILY[\"COUNT\"] == df_DATETIME_DAILY[\"COUNT\"].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### December 22, 2013 historically according to the National Post<sup>[7]</sup> was a nasty ice storm that left 300,000 people in Toronto Isolated\n",
    "- this was an unprecedented event\n",
    "- lets slice out this event and observe the time series plot again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use ~ NOT boolean operator to slice out the outlier\n",
    "df_DATETIME_DAILY = df_DATETIME_DAILY.loc[~(df_DATETIME_DAILY[\"COUNT\"] == df_DATETIME_DAILY[\"COUNT\"].max())]\n",
    "\n",
    "# visualize the resampled daily count time series with matplotlib\n",
    "fig, axes = plt.subplots(1, 1, figsize=(7, 3.5))\n",
    "\n",
    "# get y lim\n",
    "y_lim1 = 0\n",
    "y_lim2 = math.ceil(df_DATETIME_DAILY[\"COUNT\"].max() / 1000) * 1000\n",
    "\n",
    "# get x lim\n",
    "x_lim1 = datetime.datetime(year=2010, month=10, day=1)\n",
    "x_lim2 = datetime.datetime(year=2019, month=2, day=1)\n",
    "\n",
    "# plot the time series\n",
    "axes.plot(df_DATETIME_DAILY.index,\n",
    "          df_DATETIME_DAILY[\"COUNT\"],\n",
    "          color=\"blue\",\n",
    "          linewidth=0.5,\n",
    "          label=\"Daily Call Counts for TFS\");\n",
    "\n",
    "# set axis limits\n",
    "axes.set_xlim(x_lim1, x_lim2)\n",
    "axes.set_ylim(y_lim1, y_lim2)\n",
    "\n",
    "# set minor ticks for x axis to be the months\n",
    "months = mdates.MonthLocator()\n",
    "axes.xaxis.set_minor_locator(months)\n",
    "\n",
    "# set minor ticks for y axis to be values of 100\n",
    "fifties = tick.MultipleLocator(50)\n",
    "axes.yaxis.set_minor_locator(fifties)\n",
    "\n",
    "# set title, x axis title and y axis title\n",
    "axes.set_title(\"Daily Total Calls Received by the Toronto Fire Services (TFS)\")\n",
    "axes.set_xlabel(\"Years (2011 - 2018 range)\")\n",
    "axes.set_ylabel(\"Number of Daily Calls\")\n",
    "\n",
    "# plot a legend\n",
    "plt.legend()\n",
    "\n",
    "# magical padding\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the figure\n",
    "fig.savefig(os.path.join(IMAGES_DIRECTORY, \"Daily_Total_Calls_TFS_REMOVED_12-22-2013.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get the autocorrelation plot to see if there is a relationship\n",
    "# between successive days\n",
    "fig, axes = plt.subplots(1, 1, figsize=(7, 3.5))\n",
    "\n",
    "# get x lim (lets stop at 2 years 365)\n",
    "x_lim1 = 0\n",
    "x_lim2 = 730\n",
    "\n",
    "# get the y lim\n",
    "y_lim1 = -1\n",
    "y_lim2 = 1\n",
    "\n",
    "# autocorrelation plot\n",
    "pd.plotting.autocorrelation_plot(df_DATETIME_DAILY, ax=axes)\n",
    "\n",
    "# set the x and y limits\n",
    "axes.set_xlim(x_lim1, x_lim2)\n",
    "axes.set_ylim(y_lim1, y_lim2)\n",
    "axes.set_title(\"Daily Total Number of Calls Autocorrelation Plot\")\n",
    "\n",
    "# save the figure\n",
    "fig.savefig(os.path.join(IMAGES_DIRECTORY, \"Daily_Total_Calls_Autocorrelation.png\"))\n",
    "\n",
    "# It appears for about 300 days that there are strong correlations of Fire Incidents with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take the first order difference to see if we can introduce\n",
    "# stationarity to the time series\n",
    "df_DATETIME_DAILY_DIFF = df_DATETIME_DAILY.diff(1).dropna()\n",
    "\n",
    "# lets get the autocorrelation plot to see if there is a relationship\n",
    "# for the first order difference\n",
    "fig, axes = plt.subplots(1, 1, figsize=(7, 3.5))\n",
    "\n",
    "# get x lim (lets stop at 2 years 365)\n",
    "x_lim1 = 0\n",
    "x_lim2 = 730\n",
    "\n",
    "# get the y lim\n",
    "y_lim1 = -1\n",
    "y_lim2 = 1\n",
    "\n",
    "# autocorrelation plot\n",
    "pd.plotting.autocorrelation_plot(df_DATETIME_DAILY_DIFF, ax=axes)\n",
    "\n",
    "# set the x and y limits\n",
    "axes.set_xlim(x_lim1, x_lim2)\n",
    "axes.set_ylim(y_lim1, y_lim2)\n",
    "axes.set_title(\"Daily Total Number of Calls First Order Difference Autocorrelation Plot\")\n",
    "\n",
    "fig.savefig(os.path.join(IMAGES_DIRECTORY, \"Daily_Total_Calls_First_Order_Difference_Autocorrelation.png\"))\n",
    "\n",
    "# The Time Series is now stationary, will need to perform statistics tests\n",
    "# to make sure but visually it is clear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample dailyand get the daily count of TFS Basic Fire Incidents\n",
    "df_DATETIME_MONTHLY = df_DATETIME.resample(\"M\").count().rename(columns={\"CAD_TYPE\":\"COUNT\"})\n",
    "df_DATETIME_MONTHLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the resampled monthly count time series with matplotlib\n",
    "fig, axes = plt.subplots(1, 1, figsize=(7, 3.5))\n",
    "\n",
    "# get y lim\n",
    "y_lim1 = 0\n",
    "y_lim2 = math.ceil(df_DATETIME_MONTHLY[\"COUNT\"].max() / 1000) * 1000\n",
    "\n",
    "# get x lim\n",
    "x_lim1 = datetime.datetime(year=2010, month=10, day=1)\n",
    "x_lim2 = datetime.datetime(year=2019, month=2, day=1)\n",
    "\n",
    "# plot the time series\n",
    "axes.plot(df_DATETIME_MONTHLY.index,\n",
    "          df_DATETIME_MONTHLY[\"COUNT\"],\n",
    "          color=\"blue\",\n",
    "          linewidth=0.5,\n",
    "          label=\"Monthly Call Counts for TFS\");\n",
    "\n",
    "# set axis limits\n",
    "axes.set_xlim(x_lim1, x_lim2)\n",
    "axes.set_ylim(y_lim1, y_lim2)\n",
    "\n",
    "# set minor ticks for x axis to be the months\n",
    "months = mdates.MonthLocator()\n",
    "axes.xaxis.set_minor_locator(months)\n",
    "\n",
    "# set minor ticks for y axis to be values of 100\n",
    "hundreds = tick.MultipleLocator(100)\n",
    "axes.yaxis.set_minor_locator(hundreds)\n",
    "\n",
    "# set title, x axis title and y axis title\n",
    "axes.set_title(\"Monthly Total Calls Received by the Toronto Fire Services (TFS)\")\n",
    "axes.set_xlabel(\"Years (2011 - 2018 range)\")\n",
    "axes.set_ylabel(\"Number of Monthly Calls\")\n",
    "\n",
    "# plot a legend\n",
    "plt.legend()\n",
    "\n",
    "# magical padding\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the figure\n",
    "fig.savefig(os.path.join(IMAGES_DIRECTORY, \"Monthly_Total_Calls_TFS.png\"))\n",
    "\n",
    "# The spike on Dec. 22, 2013 is kept as it cannot be ruled an outlier\n",
    "# for monthly resampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get the autocorrelation plot to see if there is a relationship\n",
    "# between successive days\n",
    "fig, axes = plt.subplots(1, 1, figsize=(7, 3.5))\n",
    "\n",
    "# get the y lim\n",
    "y_lim1 = -1\n",
    "y_lim2 = 1\n",
    "\n",
    "# autocorrelation plot\n",
    "pd.plotting.autocorrelation_plot(df_DATETIME_MONTHLY, ax=axes)\n",
    "\n",
    "# set the x and y limits\n",
    "axes.set_ylim(y_lim1, y_lim2)\n",
    "axes.set_title(\"Monthly Total Number of Calls Autocorrelation Plot\")\n",
    "\n",
    "# save the figure\n",
    "fig.savefig(os.path.join(IMAGES_DIRECTORY, \"Monthly_Total_Calls_Autocorrelation.png\"))\n",
    "\n",
    "# autocorrelation is present for the first 7 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take the first order difference to see if we can introduce\n",
    "# stationarity to the time series\n",
    "df_DATETIME_MONTHLY_DIFF = df_DATETIME_MONTHLY.diff(1).dropna()\n",
    "\n",
    "# lets get the autocorrelation plot to see if there is a relationship\n",
    "# for the first order difference\n",
    "fig, axes = plt.subplots(1, 1, figsize=(7, 3.5))\n",
    "\n",
    "# get the y lim\n",
    "y_lim1 = -1\n",
    "y_lim2 = 1\n",
    "\n",
    "# autocorrelation plot\n",
    "pd.plotting.autocorrelation_plot(df_DATETIME_MONTHLY_DIFF, ax=axes)\n",
    "\n",
    "# set the y limits\n",
    "axes.set_ylim(y_lim1, y_lim2)\n",
    "axes.set_title(\"Monthly Total Number of Calls First Order Difference Autocorrelation Plot\")\n",
    "\n",
    "fig.savefig(os.path.join(IMAGES_DIRECTORY, \"Monthly_Total_Calls_First_Order_Difference_Autocorrelation.png\"))\n",
    "\n",
    "# No autocorrelation for First Order Difference as it appears to be stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the dataframes from memory\n",
    "del df_DATETIME, df_DATETIME_DAILY, df_DATETIME_DAILY_DIFF, df_DATETIME_MONTHLY, df_DATETIME_MONTHLY_DIFF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. The Effect of Toronto Weather / Climate on Toronto Fire Services Basic Incidents\n",
    "- What role does Toronto Weather and Climate have on TFS Basic Incidents\n",
    "    - Weather and Climate (Temperature, Rain, Precipitation, Snow levels)\n",
    "    - Building Energy Demands (Heating Degree Day (HDD)<sup>[8]</sup> and Cooling Degree Day (CDD)<sup>[]</sup>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab the aggregate statistics for the top 10 \"FINAL_TYPE\" categories\n",
    "top_10 = [x for x in df[\"FINAL_TYPE\"].value_counts().index[:10]]\n",
    "\n",
    "# generate groupby aggregate statistics\n",
    "df_TEMP_GROUPBY = (df.loc[df[\"FINAL_TYPE\"].isin(top_10), [\"MEAN_TEMP\", \"FINAL_TYPE\"]]\n",
    "                     .groupby(\"FINAL_TYPE\")\n",
    "                     .agg([\"mean\", \"std\"])\n",
    "                     .dropna()\n",
    "                     .reset_index())\n",
    "\n",
    "# rename columns\n",
    "df_TEMP_GROUPBY.columns = [\"FINAL_TYPE\", \"MEAN_TEMP\", \"STD_TEMP\"]\n",
    "\n",
    "# set the index\n",
    "df_TEMP_GROUPBY.index = df_TEMP_GROUPBY[\"FINAL_TYPE\"].apply(lambda x: x.split(\"-\")[0].strip())\n",
    "df_TEMP_GROUPBY.index.name = \"CODE\"\n",
    "\n",
    "# save the DataFrame to a csv\n",
    "df_TEMP_GROUPBY.to_csv(os.path.join(ANALYSES_DIRECTORY, \"Top_10_Calls_and_Temperature.csv\"))\n",
    "\n",
    "df_TEMP_GROUPBY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a bar plot to show the distribution of temperature for the top 10 calls\n",
    "fig, axes = plt.subplots(1, 1, figsize=(5, 3.5))\n",
    "\n",
    "# get y lim\n",
    "y_lim1 = 0\n",
    "y_lim2 = 25\n",
    "\n",
    "# plot the time series\n",
    "axes.bar(x=df_TEMP_GROUPBY.index,\n",
    "          height=df_TEMP_GROUPBY[\"MEAN_TEMP\"],\n",
    "          yerr=df_TEMP_GROUPBY[\"STD_TEMP\"],\n",
    "          color=\"blue\",\n",
    "          ecolor=\"red\")\n",
    "\n",
    "# set axis limits\n",
    "axes.set_ylim(y_lim1, y_lim2)\n",
    "\n",
    "# set title, x axis title and y axis title\n",
    "axes.set_title(\"Temperature of the Top 10 TFS Fire Incident Calls\")\n",
    "axes.set_xlabel(\"Codes of Fire Incident Calls\")\n",
    "axes.set_ylabel(\"Mean Temperature (Celsius)\")\n",
    "\n",
    "# magical padding\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the figure\n",
    "fig.savefig(os.path.join(IMAGES_DIRECTORY, \"Top_10_Calls_and_Temperature.png\"))\n",
    "\n",
    "# As you can see from the standard deviation the temperatures are all over the place\n",
    "# No relationship can be gleamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A series of Histograms for the Top 10 TFS Fire Incident Calls\n",
    "for x in top_10:\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(3.5, 3.5))\n",
    "    axes.hist(df.loc[df[\"FINAL_TYPE\"] == x, \"MEAN_TEMP\"])\n",
    "    axes.set_title(re.sub(\"(.{36})\", \"\\\\1\\n\", x, 0, re.DOTALL))\n",
    "    axes.set_xlabel(\"Temperature (Celsius)\")\n",
    "    axes.set_ylabel(\"Frequency\")\n",
    "    # save the figure without any punctuation or whitespace\n",
    "    fig.savefig(os.path.join(\n",
    "        IMAGES_DIRECTORY,\n",
    "        f\"\"\"{x.translate(str.maketrans('', '', string.punctuation)).replace(\" \", \"\")}.png\"\"\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of incidents to specific temperature ranges\n",
    "\n",
    "# get max and min temperature\n",
    "maximum_temp = df[\"MAX_TEMP\"].max()\n",
    "minimum_temp = df[\"MAX_TEMP\"].min()\n",
    "\n",
    "# get ceiling and floor\n",
    "max_ceil = math.ceil(maximum_temp/10)*10\n",
    "min_floor = math.floor(minimum_temp/10)*10\n",
    "\n",
    "# generate cutting locations and labels\n",
    "step=20\n",
    "temp_range = list(np.arange(min_floor, max_ceil+1, step))\n",
    "labels = [f\"{value} to {temp_range[index+1]}\" for (index, value) in enumerate(temp_range[:-1])]\n",
    "\n",
    "# create column with Bins\n",
    "df[\"MEAN_TEMP_BINS\"] = pd.cut(df[\"MEAN_TEMP\"],\n",
    "                                    bins=temp_range,\n",
    "                                    labels=labels)\n",
    "\n",
    "# frequency of incidents corresponding to temperatures\n",
    "df_MEAN_INCIDENTS = (df[[\"CAD_TYPE\", \"MEAN_TEMP_BINS\"]]\n",
    "                     .groupby(\"MEAN_TEMP_BINS\")\n",
    "                     .count()\n",
    "                     .rename(columns={\"CAD_TYPE\":\"Number of Incidents\"}))\n",
    "df_MEAN_INCIDENTS.index.name = \"Mean Temperature (Celsius) Bins\"\n",
    "\n",
    "# save the dataframe\n",
    "df_MEAN_INCIDENTS.to_csv(os.path.join(ANALYSES_DIRECTORY, \"Temperature_Bins_and_TFS_Incidents.csv\"))\n",
    "\n",
    "df_MEAN_INCIDENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the variables and drop the Temperature Bin\n",
    "del df_TEMP_GROUPBY\n",
    "df.drop(columns=\"MEAN_TEMP_BINS\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature varies widely among top 10 incident types\n",
    "### Frequency distribution for Incidents peaks at a temperature range of 0 to 20\n",
    "### In Conclusion I do not believe temperature plase an important role in predicting the type of incident TFS responds to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heating Degree Day (HDD) and Cooling Degree Day (CDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin the HDD and CDD data\n",
    "\n",
    "# get the max and min for HDD and CDD\n",
    "max_HDD = df[\"HDD\"].max(); min_HDD = df[\"HDD\"].min(); max_CDD = df[\"CDD\"].max(); min_CDD = df[\"CDD\"].min()\n",
    "\n",
    "# get ceiling and floor\n",
    "max_ceil_HDD = math.ceil(max_HDD/10)*10; min_floor_HDD = math.floor(min_HDD/10)*10;\n",
    "max_ceil_CDD = math.ceil(max_CDD/10)*10; min_floor_CDD = math.floor(min_CDD/10)*10;\n",
    "\n",
    "# generate HDD and CDD range\n",
    "step_HDD=5\n",
    "step_CDD=2\n",
    "HDD_range = list(np.arange(min_floor_HDD, max_ceil_HDD+1, step_HDD))\n",
    "CDD_range = list(np.arange(min_floor_CDD, max_ceil_CDD+1, step_CDD))\n",
    "\n",
    "# get the HDD and CDD labels\n",
    "labels_HDD = [f\"{value} to {HDD_range[index+1]}\" for (index, value) in enumerate(HDD_range[:-1])]\n",
    "labels_CDD = [f\"{value} to {CDD_range[index+1]}\" for (index, value) in enumerate(CDD_range[:-1])]\n",
    "\n",
    "# set the bin labels to the dataframe\n",
    "df[\"HDD_BINS\"] = pd.cut(df[\"HDD\"], bins= HDD_range, right = False, labels= labels_HDD)\n",
    "df[\"CDD_BINS\"] = pd.cut(df[\"CDD\"], bins= CDD_range, right = False, labels= labels_CDD)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GroupBy count for HDD and CDD and save to csv\n",
    "df_HDD_GROUPBY = df[[\"HDD_BINS\", \"CAD_TYPE\"]].groupby(\"HDD_BINS\").count().rename(columns={\"CAD_TYPE\":\"COUNT\"})\n",
    "df_CDD_GROUPBY = df[[\"CDD_BINS\", \"CAD_TYPE\"]].groupby(\"CDD_BINS\").count().rename(columns={\"CAD_TYPE\":\"COUNT\"})\n",
    "\n",
    "# save to csv\n",
    "df_HDD_GROUPBY.to_csv(os.path.join(ANALYSES_DIRECTORY, \"TFS_Fire_Incidents_HDD.csv\"))\n",
    "df_CDD_GROUPBY.to_csv(os.path.join(ANALYSES_DIRECTORY, \"TFS_Fire_Incidents_CDD.csv\"))\n",
    "\n",
    "display(df_HDD_GROUPBY)\n",
    "display(df_CDD_GROUPBY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a histogram of HDD and CDD\n",
    "fig, axes = plt.subplots(1, 1, figsize=(5, 3.5))\n",
    "\n",
    "# plot the time series\n",
    "axes.hist(\"HDD\", HDD_range, data=df)\n",
    "\n",
    "# set title, x axis title and y axis title\n",
    "axes.set_title(\"Frequency of Fire Incident Calls for given HDD\")\n",
    "axes.set_xlabel(\"HDD Bins (Celsius)\")\n",
    "axes.set_ylabel(\"Frequency\")\n",
    "\n",
    "# magical padding\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the figure\n",
    "fig.savefig(os.path.join(IMAGES_DIRECTORY, \"TFS_Fire_Incidents_HDD.png\"))\n",
    "\n",
    "# A good majority occur on days with minimial to no heating requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a histogram of HDD and CDD\n",
    "fig, axes = plt.subplots(1, 1, figsize=(5, 3.5))\n",
    "\n",
    "# plot the time series\n",
    "axes.hist(\"CDD\", CDD_range, data=df)\n",
    "\n",
    "# set title, x axis title and y axis title\n",
    "axes.set_title(\"Frequency of Fire Incident Calls for given CDD\")\n",
    "axes.set_xlabel(\"CDD Bins (Celsius)\")\n",
    "axes.set_ylabel(\"Frequency\")\n",
    "\n",
    "# magical padding\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the figure\n",
    "fig.savefig(os.path.join(IMAGES_DIRECTORY, \"TFS_Fire_Incidents_CDD.png\"))\n",
    "\n",
    "# A good majority occur on days with minimial to no heating requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data by month of year to see if HDD and CDD have no effect\n",
    "df_HDD_CROSSTAB = pd.crosstab(df[\"DATETIME\"].dt.month, df[\"HDD_BINS\"], df[\"DATETIME\"].dt.month, aggfunc=\"count\")\n",
    "df_HDD_CROSSTAB.index.name = \"MONTH\"\n",
    "\n",
    "# write to csv\n",
    "df_HDD_CROSSTAB.to_csv(os.path.join(ANALYSES_DIRECTORY, \"HDD_Month_Crosstab.csv\"))\n",
    "\n",
    "df_HDD_CROSSTAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDD Crosstab\n",
    "fig, axes = plt.subplots(1, 1, figsize=(7, 3.5))\n",
    "\n",
    "# plot the HDD Crosstab\n",
    "df_HDD_CROSSTAB.plot(kind=\"bar\", stacked=True, rot=0, ax=axes)\n",
    "axes.set_ylabel(\"Count\")\n",
    "axes.set_xlabel(\"Month\")\n",
    "axes.set_title(\"HDD Bins and TFS Incident Numbers per Month\")\n",
    "axes.legend(title=\"HDD Values\",bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "# save the figure\n",
    "fig.savefig(os.path.join(IMAGES_DIRECTORY, \"HDD_Month_Crosstab.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data by month of year to see if HDD and CDD have no effect\n",
    "df_CDD_CROSSTAB = pd.crosstab(df[\"DATETIME\"].dt.month, df[\"CDD_BINS\"], df[\"DATETIME\"].dt.month, aggfunc=\"count\")\n",
    "df_CDD_CROSSTAB.index.name = \"MONTH\"\n",
    "\n",
    "# write to csv\n",
    "df_CDD_CROSSTAB.to_csv(os.path.join(ANALYSES_DIRECTORY, \"CDD_Month_Crosstab.csv\"))\n",
    "\n",
    "df_CDD_CROSSTAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDD Crosstab\n",
    "fig, axes = plt.subplots(1, 1, figsize=(7, 3.5))\n",
    "\n",
    "# plot the CDD Crosstab\n",
    "df_CDD_CROSSTAB.plot(kind=\"bar\", stacked=True, rot=0, ax=axes)\n",
    "axes.set_ylabel(\"Count\")\n",
    "axes.set_xlabel(\"Month\")\n",
    "axes.set_title(\"CDD Bins and TFS Incident Numbers per Month\")\n",
    "axes.legend(title=\"CDD Values\",bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "# save the figure\n",
    "fig.savefig(os.path.join(IMAGES_DIRECTORY, \"CDD_Month_Crosstab.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete and drop variables / columns\n",
    "del df_CDD_CROSSTAB, df_HDD_CROSSTAB, df_HDD_GROUPBY, df_CDD_GROUPBY\n",
    "df.drop(columns=[\"HDD_BINS\", \"CDD_BINS\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is no discerning trend to show a relationship between HDD or CDD and number of TFS emergency calls over the months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rain and Snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin the rain and snow data\n",
    "\n",
    "# get the max and min for HDD and CDD\n",
    "max_rain = df[\"RAIN_MM\"].max(); min_rain = df[\"RAIN_MM\"].min(); max_snow = df[\"SNOW_CM\"].max(); min_snow = df[\"SNOW_CM\"].min()\n",
    "\n",
    "# get ceiling and floor\n",
    "max_ceil_rain = math.ceil(max_rain/10)*10; min_floor_rain = math.floor(min_rain/10)*10;\n",
    "max_ceil_snow = math.ceil(max_snow/10)*10; min_floor_snow = math.floor(min_snow/10)*10;\n",
    "\n",
    "# generate HDD and CDD range\n",
    "step_rain=5\n",
    "step_snow=5\n",
    "rain_range = list(np.arange(min_floor_rain, max_ceil_rain+1, step_rain))\n",
    "snow_range = list(np.arange(min_floor_snow, max_ceil_snow+1, step_snow))\n",
    "\n",
    "# get the HDD and CDD labels\n",
    "labels_rain = [f\"{value} to {rain_range[index+1]}\" for (index, value) in enumerate(rain_range[:-1])]\n",
    "labels_snow = [f\"{value} to {snow_range[index+1]}\" for (index, value) in enumerate(snow_range[:-1])]\n",
    "\n",
    "# set the bin labels to the dataframe\n",
    "df[\"RAIN_BINS\"] = pd.cut(df[\"RAIN_MM\"], bins= rain_range, right = False, labels= labels_rain)\n",
    "df[\"SNOW_BINS\"] = pd.cut(df[\"SNOW_CM\"], bins= snow_range, right = False, labels= labels_snow)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GroupBy count for HDD and CDD and save to csv\n",
    "df_RAIN_GROUPBY = df[[\"RAIN_BINS\", \"CAD_TYPE\"]].groupby(\"RAIN_BINS\").count().rename(columns={\"CAD_TYPE\":\"COUNT\"})\n",
    "df_SNOW_GROUPBY = df[[\"SNOW_BINS\", \"CAD_TYPE\"]].groupby(\"SNOW_BINS\").count().rename(columns={\"CAD_TYPE\":\"COUNT\"})\n",
    "\n",
    "# save to csv\n",
    "df_RAIN_GROUPBY.to_csv(os.path.join(ANALYSES_DIRECTORY, \"TFS_Fire_Incidents_RAIN.csv\"))\n",
    "df_SNOW_GROUPBY.to_csv(os.path.join(ANALYSES_DIRECTORY, \"TFS_Fire_Incidents_SNOW.csv\"))\n",
    "\n",
    "display(df_RAIN_GROUPBY)\n",
    "display(df_SNOW_GROUPBY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a histogram of HDD and CDD\n",
    "fig, axes = plt.subplots(1, 1, figsize=(5, 3.5))\n",
    "\n",
    "# plot the time series\n",
    "axes.hist(\"RAIN_MM\", rain_range, data=df)\n",
    "\n",
    "# set title, x axis title and y axis title\n",
    "axes.set_title(\"Frequency of Fire Incident Calls for given mm of Rain\")\n",
    "axes.set_xlabel(\"Rain Bins (mm)\")\n",
    "axes.set_ylabel(\"Frequency\")\n",
    "\n",
    "# magical padding\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the figure\n",
    "fig.savefig(os.path.join(IMAGES_DIRECTORY, \"TFS_Fire_Incidents_Rain.png\"))\n",
    "\n",
    "# A good majority occur on days with no rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a histogram of HDD and CDD\n",
    "fig, axes = plt.subplots(1, 1, figsize=(5, 3.5))\n",
    "\n",
    "# plot the time series\n",
    "axes.hist(\"SNOW_CM\", snow_range, data=df)\n",
    "\n",
    "# set title, x axis title and y axis title\n",
    "axes.set_title(\"Frequency of Fire Incident Calls for given cm of Snow\")\n",
    "axes.set_xlabel(\"Snow Bins (cm)\")\n",
    "axes.set_ylabel(\"Frequency\")\n",
    "\n",
    "# magical padding\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the figure\n",
    "fig.savefig(os.path.join(IMAGES_DIRECTORY, \"TFS_Fire_Incidents_Snow.png\"))\n",
    "\n",
    "# A good majority occur on days with no snow on the ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data by month of year to see if rain or snow have an effect\n",
    "df_RAIN_CROSSTAB = pd.crosstab(df[\"DATETIME\"].dt.month, df[\"RAIN_BINS\"], df[\"DATETIME\"].dt.month, aggfunc=\"count\")\n",
    "df_RAIN_CROSSTAB.index.name = \"MONTH\"\n",
    "\n",
    "# write to csv\n",
    "df_RAIN_CROSSTAB.to_csv(os.path.join(ANALYSES_DIRECTORY, \"RAIN_Month_Crosstab.csv\"))\n",
    "\n",
    "df_RAIN_CROSSTAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rain Crosstab\n",
    "fig, axes = plt.subplots(1, 1, figsize=(7, 3.5))\n",
    "\n",
    "# plot the Rain Crosstab\n",
    "df_RAIN_CROSSTAB.plot(kind=\"bar\", stacked=True, rot=0, ax=axes)\n",
    "axes.set_ylabel(\"Count\")\n",
    "axes.set_xlabel(\"Month\")\n",
    "axes.set_title(\"Rain Bins and TFS Incident Numbers per Month\")\n",
    "axes.legend(title=\"Rain Values\",bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "# save the figure\n",
    "fig.savefig(os.path.join(IMAGES_DIRECTORY, \"Rain_Month_Crosstab.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data by month of year to see if rain or snow have an effect\n",
    "df_SNOW_CROSSTAB = pd.crosstab(df[\"DATETIME\"].dt.month, df[\"SNOW_BINS\"], df[\"DATETIME\"].dt.month, aggfunc=\"count\")\n",
    "df_SNOW_CROSSTAB.index.name = \"MONTH\"\n",
    "\n",
    "# write to csv\n",
    "df_SNOW_CROSSTAB.to_csv(os.path.join(ANALYSES_DIRECTORY, \"SNOW_Month_Crosstab.csv\"))\n",
    "\n",
    "df_SNOW_CROSSTAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snow Crosstab\n",
    "fig, axes = plt.subplots(1, 1, figsize=(7, 3.5))\n",
    "\n",
    "# plot the Snow Crosstab\n",
    "df_SNOW_CROSSTAB.plot(kind=\"bar\", stacked=True, rot=0, ax=axes)\n",
    "axes.set_ylabel(\"Count\")\n",
    "axes.set_xlabel(\"Month\")\n",
    "axes.set_title(\"Snow Bins and TFS Incident Numbers per Month\")\n",
    "axes.legend(title=\"Snow Values\",bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "# save the figure\n",
    "fig.savefig(os.path.join(IMAGES_DIRECTORY, \"Snow_Month_Crosstab.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snow and Rain have no real impact on TFS Fire Incidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. The effect if Time and Day of the Week on TFS Fire Incidents\n",
    "- do specific days of the week or times of the day affect the number of TFS Fire Incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Jupyter Notebook References\n",
    "\n",
    "[1] \"Python Documentation.\"  *Python Software Foundation*.  [Online](https://docs.python.org/).  [Accessed August 04, 2020]\n",
    "\n",
    "[2] G. Niemeyer.  \"dateutil - powerful extensions to datetime.\"  *dateutil*.  [Online](https://github.com/dateutil/dateutil).  [Accessed August 04, 2020]\n",
    "\n",
    "[3] \"pandas.\"  *PyData*.  [Online](https://pandas.pydata.org/).  [Accessed August 04, 2020]\n",
    "\n",
    "[4] \"NumPy - The fundamental package for scientific computing with Python.\"  *NumPy*.  [Online](https://numpy.org/).  [Accessed August 04, 2020]\n",
    "\n",
    "[5] \"Matplotlib:  Visualization with Python.\"  *The Matplotlib Development team*.  [Online](https://matplotlib.org/).  [Accessed August 04, 2020]\n",
    "\n",
    "[6] M. Waskom.  \"seaborn:  statistical data visualization.\"  *seaborn*.  [Online](https://seaborn.pydata.org/).  [Accessed August 04, 2020]\n",
    "\n",
    "[7] \"Toronto ice storm 2013: Photos show city looking like crime scene with taped-off downed branches.\"  *National Post*. December 23, 2013. [Online](https://nationalpost.com/news/canada/toronto-ice-storm-2013-photos-from-the-gtas-winter-nightmare).  [Accessed August 04, 2020]\n",
    "\n",
    "[8] \"Heating degree day.\" *Wikipedia*.  [Online](https://en.wikipedia.org/wiki/Heating_degree_day).  [Accessed August 04, 2020]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[6] \"City of Toronto Open Data Portal.\"  *City of Toronto*.  [Online](https://open.toronto.ca/).  [Accessed August 04, 2020]\n",
    "\n",
    "[7] \"Fire Services Basic Incident Details.\"  *City of Toronto*.  [Online](https://open.toronto.ca/dataset/fire-services-basic-incident-details/).  [Accessed August 04, 2020]\n",
    "\n",
    "[8] \"Historical Climate Data.\"  *Government of Canada*.  [Online](https://climate.weather.gc.ca/).  [Accessed August 04, 2020]\n",
    "\n",
    "[9] \"URL based procedure to automatically download data in bulk from Climate Website\"  *Government of Canada*.  [Online].  *ftp://client_climate@ftp.tor.ec.gc.ca/Pub/Get_More_Data_Plus_de_donnees/Readme.txt*.  [Accessed August 04, 2020]\n",
    "\n",
    "[10] \"Fire Station Locations.\"  *City of Toronto*.  [Online](https://open.toronto.ca/dataset/fire-station-locations/).  [Accessed August 04, 2020]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
